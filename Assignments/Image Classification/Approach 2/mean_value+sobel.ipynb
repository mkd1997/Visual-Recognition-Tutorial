{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here we aim to classify images into daylight landscapes, nightlight landscapes and portraits by designing features and using kNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image resizing\n",
    "\n",
    "Since we aim to use Sobel filter to generate feature vectors, it is necessary to resize all the images to the same dimensions so that the generated feature vectors are of same length. Resizing a image may cause loss of information. To minimize this loss as well as avoid padding any image, we resize all the images to the minimum height and width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum dimensions\n",
    "def get_min_dimensions():\n",
    "    MIN_WIDTH = 500\n",
    "    MIN_HEIGHT = 500\n",
    "    for class_folder in ['portrait', 'day-landscape', 'night-landscape']:        \n",
    "        for file in os.listdir('../Train Images/' + class_folder):\n",
    "            img = cv2.imread('../Train Images/' + class_folder + '/' + file)\n",
    "            if (img.shape[0] < MIN_HEIGHT):\n",
    "                MIN_HEIGHT = img.shape[0]\n",
    "            if (img.shape[1] < MIN_WIDTH):\n",
    "                MIN_WIDTH = img.shape[1]\n",
    "    \n",
    "    for file in os.listdir('../Test Images/'):\n",
    "        img = cv2.imread('../Test Images/' + file)\n",
    "        if (img.shape[0] < MIN_HEIGHT):\n",
    "            MIN_HEIGHT = img.shape[0]\n",
    "        if (img.shape[1] < MIN_WIDTH):\n",
    "            MIN_WIDTH = img.shape[1]\n",
    "        \n",
    "    return (MIN_HEIGHT, MIN_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "def resize_images(img, min_dims):\n",
    "    resized_img = cv2.resize(img, min_dims, cv2.INTER_AREA)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average brightness\n",
    "\n",
    "In the HSV colorspace, the 'value' of each pixel corresponds to the brightness of that pixel. Since, we know that night landscapes are inherently dark and vice versa, we can use average value of the images as a feature to distinguish between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean value\n",
    "def get_mean_value(img):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mean_value = np.mean(hsv_img[:,:,2])\n",
    "    return hsv_img, mean_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical Sobel filter\n",
    "\n",
    "We know that, in a portrait image, there would be significant number of vertical edges as compared to a landscape image. Thus, we use Sobel filter responses as a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sobel filter\n",
    "def apply_sobel(img):\n",
    "    blur_img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    gray_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2GRAY)\n",
    "    grad_y = cv2.Sobel(gray_img, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    abs_gray_y = cv2.convertScaleAbs(grad_y)\n",
    "    return abs_gray_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 182)\n"
     ]
    }
   ],
   "source": [
    "# image preprocessing\n",
    "min_dims = get_min_dimensions()\n",
    "print(min_dims)\n",
    "for class_folder in ['portrait', 'day-landscape', 'night-landscape']:        \n",
    "    for file in os.listdir('../Train Images/' + class_folder):\n",
    "#         print(file)\n",
    "        img = cv2.imread('../Train Images/' + class_folder + '/' + file)\n",
    "        resize_image = resize_images(img, min_dims)\n",
    "        plt.imsave('./Resized Images/' + class_folder + '/' + file, resize_image)\n",
    "\n",
    "for file in os.listdir('../Test Images/'):\n",
    "#     print(file)\n",
    "    img = cv2.imread('../Test Images/' + file)\n",
    "    resize_image = resize_images(img, min_dims)\n",
    "    plt.imsave('./Resized Images/Test Images/' + file, resize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 25117) (42,)\n"
     ]
    }
   ],
   "source": [
    "# class dictionary\n",
    "class_dict = {\n",
    "    'portrait': 0,\n",
    "    'day-landscape': 1,\n",
    "    'night-landscape': 2\n",
    "}\n",
    "\n",
    "# get image features\n",
    "train_feats = []\n",
    "labels = []\n",
    "\n",
    "for class_folder in ['portrait', 'day-landscape', 'night-landscape']:\n",
    "    for file in os.listdir('./Resized Images/' + class_folder):\n",
    "        img = cv2.imread('./Resized Images/' + class_folder + '/' + file)\n",
    "        hsv_img, mean_value = get_mean_value(img)\n",
    "        plt.imsave('./HSV Images/' + class_folder + '/' + file, hsv_img)\n",
    "        abs_gray_y = apply_sobel(img)\n",
    "        plt.imsave('./Sobel Responses/' + class_folder + '/' + file, abs_gray_y, cmap='gray')\n",
    "        abs_gray_y_flatten = abs_gray_y.flatten()\n",
    "        abs_gray_y_flatten_list = abs_gray_y_flatten.tolist()\n",
    "        abs_gray_y_flatten_list.append(mean_value)\n",
    "        feat_vec = np.array(abs_gray_y_flatten_list)\n",
    "        train_feats.append(feat_vec)\n",
    "        labels.append(class_folder)        \n",
    "\n",
    "train_feats = np.array(train_feats, dtype=np.float32)\n",
    "\n",
    "\n",
    "labels = list(map(lambda class_label : class_dict.get(class_label), labels))\n",
    "labels = np.array(labels, dtype=np.float32)\n",
    "print(train_feats.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 25117)\n"
     ]
    }
   ],
   "source": [
    "# get test features\n",
    "test_feats = []\n",
    "test_file_names = []\n",
    "for file in os.listdir('./Resized Images/Test Images'):\n",
    "    img = cv2.imread('./Resized Images/Test Images/' + file)\n",
    "    hsv_img, mean_value = get_mean_value(img)\n",
    "    plt.imsave('./HSV Images/Test Images/' + file, hsv_img)\n",
    "    abs_gray_y = apply_sobel(img)\n",
    "    plt.imsave('./Sobel Responses/Test Images/' + file, abs_gray_y, cmap='gray')\n",
    "    abs_gray_y_flatten = abs_gray_y.flatten()\n",
    "    abs_gray_y_flatten_list = abs_gray_y_flatten.tolist()\n",
    "    abs_gray_y_flatten_list.append(mean_value)\n",
    "    feat_vec = np.array(abs_gray_y_flatten_list)\n",
    "    test_feats.append(feat_vec)\n",
    "    test_file_names.append(file)\n",
    "    \n",
    "test_feats = np.array(test_feats, dtype=np.float32)\n",
    "\n",
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train knn classifier\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train_feats, cv2.ml.ROW_SAMPLE, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  [[2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]]\n",
      " ['test_1.jpeg', 'test_10.jpeg', 'test_11.jpeg', 'test_12.jpeg', 'test_2.jpeg', 'test_3.jpeg', 'test_4.jpeg', 'test_5.jpeg', 'test_6.jpeg', 'test_7.jpeg', 'test_8.jpeg', 'test_9.jpeg']\n"
     ]
    }
   ],
   "source": [
    "# test kNN\n",
    "ret, results, neighbours ,dist = knn.findNearest(test_feats, 3)\n",
    "print( \"result:  {}\\n\".format(results), test_file_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
