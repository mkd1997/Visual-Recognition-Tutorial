{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here we aim to classify images into daylight landscapes, nightlight landscapes and portraits by designing features and using kNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minimum dimensions\n",
    "def get_min_dimensions():\n",
    "    MIN_WIDTH = 500\n",
    "    MIN_HEIGHT = 500\n",
    "    for class_folder in ['portrait', 'day-landscape', 'night-landscape']:        \n",
    "        for file in os.listdir('../Train Images/' + class_folder):\n",
    "            img = cv2.imread('../Train Images/' + class_folder + '/' + file)\n",
    "            if (img.shape[0] < MIN_HEIGHT):\n",
    "                MIN_HEIGHT = img.shape[0]\n",
    "            if (img.shape[1] < MIN_WIDTH):\n",
    "                MIN_WIDTH = img.shape[1]\n",
    "    \n",
    "    for file in os.listdir('../Test Images/'):\n",
    "        img = cv2.imread('../Test Images/' + file)\n",
    "        if (img.shape[0] < MIN_HEIGHT):\n",
    "            MIN_HEIGHT = img.shape[0]\n",
    "        if (img.shape[1] < MIN_WIDTH):\n",
    "            MIN_WIDTH = img.shape[1]\n",
    "        \n",
    "    return (MIN_HEIGHT, MIN_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images\n",
    "def resize_images(img, min_dims):\n",
    "    resized_img = cv2.resize(img, min_dims, cv2.INTER_AREA)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean value\n",
    "def get_mean_value(img):\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mean_value = np.mean(hsv_img[:,:,2])\n",
    "    return hsv_img, mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sobel filter\n",
    "def apply_sobel(img):\n",
    "    blur_img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    gray_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2GRAY)\n",
    "    grad_y = cv2.Sobel(gray_img, cv2.CV_16S, 1, 0, ksize=3, scale=1, delta=0, borderType=cv2.BORDER_DEFAULT)\n",
    "    abs_gray_y = cv2.convertScaleAbs(grad_y)\n",
    "    return abs_gray_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 182)\n"
     ]
    }
   ],
   "source": [
    "# image preprocessing\n",
    "min_dims = get_min_dimensions()\n",
    "print(min_dims)\n",
    "for class_folder in ['portrait', 'day-landscape', 'night-landscape']:        \n",
    "    for file in os.listdir('../Train Images/' + class_folder):\n",
    "#         print(file)\n",
    "        img = cv2.imread('../Train Images/' + class_folder + '/' + file)\n",
    "        resize_image = resize_images(img, min_dims)\n",
    "        plt.imsave('./Resized Images/' + class_folder + '/' + file, resize_image)\n",
    "\n",
    "for file in os.listdir('../Test Images/'):\n",
    "#     print(file)\n",
    "    img = cv2.imread('../Test Images/' + file)\n",
    "    resize_image = resize_images(img, min_dims)\n",
    "    plt.imsave('./Resized Images/Test Images/' + file, resize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 25117) (42,)\n"
     ]
    }
   ],
   "source": [
    "# class dictionary\n",
    "class_dict = {\n",
    "    'portrait': 0,\n",
    "    'day-landscape': 1,\n",
    "    'night-landscape': 2\n",
    "}\n",
    "\n",
    "# get image features\n",
    "train_feats = []\n",
    "labels = []\n",
    "\n",
    "for class_folder in ['portrait', 'day-landscape', 'night-landscape']:\n",
    "    for file in os.listdir('./Resized Images/' + class_folder):\n",
    "        img = cv2.imread('./Resized Images/' + class_folder + '/' + file)\n",
    "        hsv_img, mean_value = get_mean_value(img)\n",
    "        plt.imsave('./HSV Images/' + class_folder + '/' + file, hsv_img)\n",
    "        abs_gray_y = apply_sobel(img)\n",
    "        plt.imsave('./Sobel Responses/' + class_folder + '/' + file, abs_gray_y, cmap='gray')\n",
    "        abs_gray_y_flatten = abs_gray_y.flatten()\n",
    "        abs_gray_y_flatten_list = abs_gray_y_flatten.tolist()\n",
    "        abs_gray_y_flatten_list.append(mean_value)\n",
    "        feat_vec = np.array(abs_gray_y_flatten_list)\n",
    "        train_feats.append(feat_vec)\n",
    "        labels.append(class_folder)        \n",
    "\n",
    "train_feats = np.array(train_feats, dtype=np.float32)\n",
    "\n",
    "\n",
    "labels = list(map(lambda class_label : class_dict.get(class_label), labels))\n",
    "labels = np.array(labels, dtype=np.float32)\n",
    "print(train_feats.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 25117)\n"
     ]
    }
   ],
   "source": [
    "# get test features\n",
    "test_feats = []\n",
    "for file in os.listdir('./Resized Images/Test Images'):\n",
    "    img = cv2.imread('./Resized Images/Test Images/' + file)\n",
    "    hsv_img, mean_value = get_mean_value(img)\n",
    "    plt.imsave('./HSV Images/Test Images/' + file, hsv_img)\n",
    "    abs_gray_y = apply_sobel(img)\n",
    "    plt.imsave('./Sobel Responses/Test Images/' + file, abs_gray_y, cmap='gray')\n",
    "    abs_gray_y_flatten = abs_gray_y.flatten()\n",
    "    abs_gray_y_flatten_list = abs_gray_y_flatten.tolist()\n",
    "    abs_gray_y_flatten_list.append(mean_value)\n",
    "    feat_vec = np.array(abs_gray_y_flatten_list)\n",
    "    test_feats.append(feat_vec)\n",
    "    \n",
    "test_feats = np.array(test_feats, dtype=np.float32)\n",
    "\n",
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 25117)\n"
     ]
    }
   ],
   "source": [
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 10)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply PCA\n",
    "# full_feats = np.append(train_feats, test_feats, axis=0)\n",
    "# # mean = np.empty((0))\n",
    "# mean, eigenvectors, eigenvalues = cv2.PCACompute2(full_feats, mean=None, )\n",
    "\n",
    "# # print(full_feats.shape, eigenvectors.shape, eigenvalues)\n",
    "\n",
    "kPCA = KernelPCA(n_components=10, kernel='rbf')\n",
    "transformed_train_feats = kPCA.fit_transform(train_feats)\n",
    "\n",
    "transformed_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train knn classifier\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(transformed_train_feats, cv2.ml.ROW_SAMPLE, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 10)\n"
     ]
    }
   ],
   "source": [
    "# transform test features\n",
    "transformed_test_feats = kPCA.transform(test_feats)\n",
    "print(transformed_test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test kNN\n",
    "ret, results, neighbours ,dist = knn.findNearest(transformed_test_feats, 3)\n",
    "print( \"result:  {}\\n\".format(results) )\n",
    "# print( \"neighbours:  {}\\n\".format(neighbours) )\n",
    "# print( \"distance:  {}\\n\".format(dist) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
